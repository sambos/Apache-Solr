SOLR_LOCATOR : {
  # Name of solr collection
  collection : eventscollection

  # ZooKeeper ensemble
  zkHost : "$ZK_HOST"
}

morphlines : [
  {
    id : morphline11
    importCommands : ["org.kitesdk.**", "org.apache.solr.**"]
    commands : [

	{
		readAvroContainer {
		  # Optionally, require the input to match one of these MIME types:
		   #supportedMimeTypes : [avro/binary]

		  # Optionally, use this Avro schema in JSON format inline for reading:
		  #readerSchemaString : """{"type":"record","name":"Event","fields":[{"name":"headers","type":{"type":"map","values":"string"}},{"name":"body","type":"bytes"}]}"""

		  # Optionally, use this Avro schema file in JSON format for reading:
		  # readerSchemaFile : /path/to/syslog.avsc
		}
		
	}
	{		
		extractAvroPaths {
		  flatten : true
		  paths : {
			  event : /data
		  }
		}		
	}


}
		{
		java {
					imports : """
					import com.fasterxml.jackson.databind.JsonNode;
					import org.kitesdk.morphline.base.Fields;
					import java.util.Arrays;
					import java.util.HashMap;
					import java.util.Iterator;
					import java.util.Map;
					import java.util.regex.Matcher;
					import java.util.regex.Pattern;
					import java.text.SimpleDateFormat;
					import java.util.Date;					
				  """
				code: """

				String kvPattern = "(\\w+)=\"([^\"]*)\"";
				String[] validFields = { "id","eventId", "time", "user", "client", "ip" };
				Map<String, String> map = new HashMap<String,String>();
				
				String line = new String((byte[]) record.getFirstValue("event"), "UTF-8");
				record.put("event", line);
				  if (line == null || line.isEmpty())
					return null;
					
				m = Pattern.compile(kvPattern).matcher(line);
				while (m.find()) {
					//record.put(m.group(1).toLowerCase(), m.group(2));
					map.put(m.group(1), m.group(2));
				}				

					map.put("eventId", map.get("X_ID"));
					map.put("time", map.get("LOG_TIME"));
					map.put("user", map.get("USER"));
					map.put("client", map.get("CLIENTIP"));
					map.put("ip", map.get("HOST"));

        //only retain valid fields, ignore rest
				map.keySet().retainAll(Arrays.asList(validFields));
		
				for (Iterator<String> it = map.keySet().iterator(); it.hasNext();) {
					String key = it.next();					
					record.put(key, map.get(key));
				}				

				return child.process(record);
				"""
			}
		}
		
      {
		convertTimestamp {
		  field : start
		  inputFormats : ["yyyy-MM-dd HH:mm:ss,SSS", "yyyy-MM-dd'T'HH:mm:ss,SSS"]
		  inputTimezone : UTC
		  outputFormat : "yyyy-MM-dd'T'HH:mm:ss.SSS'Z'"
		  outputTimezone : UTC
		}      
      }
      
      {
		convertTimestamp {
		  field : end
		  inputFormats : ["yyyy-MM-dd HH:mm:ss,SSS", "yyyy-MM-dd'T'HH:mm:ss,SSS"]
		  inputTimezone : UTC
		  outputFormat : "yyyy-MM-dd'T'HH:mm:ss.SSS'Z'"
		  outputTimezone : UTC
		}      
      }  

        {
                generateUUID {
                  field : id
                }
        }


		{
			removeFields {
			  blacklist : ["literal:message","literal:event"]
			
			}
		}      
      
	  { logDebug { format : "output record last: {}", args : ["@{}"] } }   
      

      { # Remove record fields that are unknown to Solr schema.xml.
        # Recall that Solr throws an exception on any attempt to load a document that
        # contains a field that isn't specified in schema.xml.
        sanitizeUnknownSolrFields {
          solrLocator : ${SOLR_LOCATOR} # Location from which to fetch Solr schema
        }
      }

      {
        loadSolr {
          solrLocator : ${SOLR_LOCATOR}
        }
      }

    ]
  }
]

